{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from simple_salesforce import Salesforce as sf\n",
    "import teradatasql\n",
    "\n",
    "login_sf = sf(username = 'intl_sales_ops_analysts@groupon.com', password = 'BA_intl_grp_3', security_token = 'ryDPBLSTkb54qbEY06GJSiA0')\n",
    "con = teradatasql.connect(host='tdwd.group.on',user='ub_intl_sales_ops',password='BA_intl_grp_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the data that needs to be processed, as set up in Teradata\n",
    "pds_boost_data = pd.read_sql(\"SELECT account_id,pds_boost_flag,required_service,load_date FROM sandbox.pds_boost_account_flags WHERE load_date = (SELECT Max(load_date) FROM sandbox.pds_boost_account_flags)\",con)\n",
    "\n",
    "pds_boost_data['account_id'] = pds_boost_data['account_id'].str.strip()\n",
    "td_account_ids = pds_boost_data['account_id'].tolist()\n",
    "td_pds_boost_flags = pds_boost_data['pds_boost_flag'].tolist()\n",
    "td_required_services = pds_boost_data['required_service'].tolist()\n",
    "td_load_dates = pds_boost_data['load_date'].tolist()\n",
    "\n",
    "data = {\n",
    "    'td_account_id': td_account_ids,\n",
    "    'td_pds_boost_flag': td_pds_boost_flags,\n",
    "    'td_required_service': td_required_services,\n",
    "    'td_load_date': td_load_dates    \n",
    "}\n",
    "\n",
    "td_pds_boost_data_table = pd.DataFrame(data)\n",
    "print(td_pds_boost_data_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the SF data table\n",
    "soql_output = login_sf.query(\"SELECT Account_ID_18__c,PDS_Boost_Summary__c,PDS_Boost_Date__c,PDS_Boost__c FROM Account WHERE PDS_Boost_Summary__c != null\")\n",
    "\n",
    "sf_account_ids = []\n",
    "sf_pds_boost_flags = []\n",
    "sf_required_services = []\n",
    "sf_load_dates = []\n",
    "\n",
    "for row in soql_output['records']:\n",
    "    sf_account_id = row['Account_ID_18__c']\n",
    "    sf_account_ids.append(sf_account_id)\n",
    "    sf_pds_boost_flag = row['PDS_Boost__c']\n",
    "    sf_pds_boost_flags.append(sf_pds_boost_flag)\n",
    "    sf_required_service = row['PDS_Boost_Summary__c']\n",
    "    sf_required_services.append(sf_required_service)\n",
    "    sf_load_date = row['PDS_Boost_Date__c']\n",
    "    sf_load_dates.append(sf_load_date)\n",
    "\n",
    "data = {\n",
    "    'sf_account_id': sf_account_ids,\n",
    "    'sf_pds_boost_flag': sf_pds_boost_flags,\n",
    "    'sf_required_service': sf_required_services,\n",
    "    'sf_load_date': sf_load_dates    \n",
    "}\n",
    "\n",
    "sf_pds_boost_data_table = pd.DataFrame(data)\n",
    "print(sf_pds_boost_data_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data prep for the 'Delete Step' \n",
    "### Data from TD And SF is joined\n",
    "df1 = sf_pds_boost_data_table.merge(td_pds_boost_data_table, left_on='sf_account_id', right_on='td_account_id', how='left')\n",
    "\n",
    "# filter is being applied to only have accounts that need to be deleted\n",
    "df1 = df1[(df1['td_account_id'].isnull())]\n",
    "\n",
    "# this drops unnecesary columns\n",
    "df1.drop('td_account_id', axis=1, inplace=True)\n",
    "df1.drop('td_pds_boost_flag', axis=1, inplace=True)\n",
    "df1.drop('sf_load_date', axis=1, inplace=True)\n",
    "df1.drop('sf_required_service', axis=1, inplace=True)\n",
    "\n",
    "# columns are renamed to fit Salesforce names\n",
    "df1.columns = ['Account_ID_18__c','PDS_Boost__c','PDS_Boost_Summary__c','PDS_Boost_Date__c']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data prep for the 'Update Step'\n",
    "### Data from TD And SF is joined\n",
    "df = td_pds_boost_data_table.merge(sf_pds_boost_data_table,left_on='td_account_id', right_on='sf_account_id', how='left')\n",
    "\n",
    "# filter is being applied to only have accounts that need to be deleted\n",
    "df2 = df[((df['sf_required_service'] == df['td_required_service']) & (df['sf_load_date'] != df['td_load_date']))] # data where only a date change is needed\n",
    "df3 = df[(df['sf_required_service'] != df['td_required_service'])] # data where a full change is needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data prep for date change\n",
    "# this drops unnecesary columns\n",
    "df2.drop('sf_account_id', axis=1, inplace=True)\n",
    "df2.drop('td_pds_boost_flag', axis=1, inplace=True)\n",
    "df2.drop('sf_pds_boost_flag', axis=1, inplace=True)\n",
    "df2.drop('sf_required_service', axis=1, inplace=True)\n",
    "df2.drop('td_required_service', axis=1, inplace=True)\n",
    "df2.drop('sf_load_date', axis=1, inplace=True)\n",
    "\n",
    "df2['td_load_date'] = df2['td_load_date'].astype(str)\n",
    "\n",
    "# columns are renamed to fit Salesforce names\n",
    "df2.columns = ['Account_ID_18__c','PDS_Boost_Date__c']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data prep for full change\n",
    "# this drops unnecesary columns\n",
    "df3.drop('sf_account_id', axis=1, inplace=True)\n",
    "df3.drop('td_pds_boost_flag', axis=1, inplace=True)\n",
    "df3.drop('sf_load_date', axis=1, inplace=True)\n",
    "df3.drop('sf_required_service', axis=1, inplace=True)\n",
    "\n",
    "df3['td_load_date'] = df3['td_load_date'].astype(str)\n",
    "\n",
    "# columns are renamed to fit Salesforce names\n",
    "df3.columns = ['Account_ID_18__c','PDS_Boost_Summary__c','PDS_Boost_Date__c','PDS_Boost__c']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data is prepared for upload in SF\n",
    "df1_ready_for_upload = []\n",
    "\n",
    "for row in df1.itertuples():\n",
    "    d = row._asdict()\n",
    "    del d['Index']\n",
    "    df1_ready_for_upload.append(d)\n",
    "    \n",
    "### data is uploaded into salesforce\n",
    "for row in df1_ready_for_upload:\n",
    "    row['PDS_Boost_Summary__c'] = None\n",
    "    row['PDS_Boost_Date__c'] = None\n",
    "    row['PDS_Boost__c'] = 'false'\n",
    "    login_sf.Account.update(row['Account_ID_18__c'],{'PDS_Boost__c':row['PDS_Boost__c'],'PDS_Boost_Summary__c':row['PDS_Boost_Summary__c'],'PDS_Boost_Date__c':row['PDS_Boost_Date__c']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data is prepared for upload in SF\n",
    "df2_ready_for_upload = []\n",
    "\n",
    "for row in df2.itertuples():\n",
    "    d = row._asdict()\n",
    "    del d['Index']\n",
    "    df2_ready_for_upload.append(d)\n",
    "\n",
    "### data is uploaded into salesforce\n",
    "for row in df2_ready_for_upload:\n",
    "      login_sf.Account.update(row['Account_ID_18__c'],{'PDS_Boost_Date__c':row['PDS_Boost_Date__c']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data is prepared for upload in SF\n",
    "df3_ready_for_upload = []\n",
    "\n",
    "for row in df3.itertuples():\n",
    "    d = row._asdict()\n",
    "    del d['Index']\n",
    "    df3_ready_for_upload.append(d)\n",
    "\n",
    "### data is uploaded into salesforce\n",
    "for row in df3_ready_for_upload:\n",
    "    row['PDS_Boost__c'] = 'true'\n",
    "    login_sf.Account.update(row['Account_ID_18__c'],{'PDS_Boost__c':row['PDS_Boost__c'],'PDS_Boost_Summary__c':row['PDS_Boost_Summary__c'],'PDS_Boost_Date__c':row['PDS_Boost_Date__c']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Success')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "414c148522c3452b8bca3bc99b333facd4b5aaa0d0e2364d6105bb7336ba2f62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
