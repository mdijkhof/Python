{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [account_id, current_owner_id, employee_sf_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from simple_salesforce import bulk\n",
    "from simple_salesforce import Salesforce as sf\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import teradatasql\n",
    "import numpy as np\n",
    "\n",
    "### This is the BUMBLEBEE output in a dataframe\n",
    "# connect and query Teradata\n",
    "con = teradatasql.connect(host='141.206.0.6',user='ub_intl_sales_ops',password='BA_intl_grp_4')\n",
    "\n",
    "bumblebee = pd.read_sql('SELECT DISTINCT account_id,current_owner_id,employee_sf_id FROM sandbox.bumblebee_output where employee_sf_id IS NOT NULL',con)\n",
    "bumblebee['account_id'] = bumblebee['account_id'].str.strip()\n",
    "\n",
    "print(bumblebee)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data in Bumblebee\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### This is the current account ownership in SF\n",
    "login_sf = sf(username = 'intl_sales_ops_analysts@groupon.com', password = 'BA_intl_grp_3', security_token = 'ryDPBLSTkb54qbEY06GJSiA0')\n",
    "\n",
    "# define variables\n",
    "account_ids = bumblebee['account_id'].tolist()\n",
    "owner_ids = []\n",
    "change_dates = []\n",
    "\n",
    "# get data from SOQL query and add to dictionary\n",
    "for account_id in account_ids:\n",
    "    soql_output = login_sf.query(f\"SELECT Account_ID_18__c,OwnerId,Acct_Owner_Change_Date__c FROM Account where Account_ID_18__c = '{account_id}'\")\n",
    "    owner_id = soql_output['records'][0]['OwnerId']\n",
    "    owner_ids.append(owner_id)\n",
    "    change_date = soql_output['records'][0]['Acct_Owner_Change_Date__c']\n",
    "    change_dates.append(change_date)\n",
    "    \n",
    "data = {\n",
    "    'account_id': account_ids,\n",
    "    'owner_id': owner_ids,\n",
    "    'change_date': change_dates\n",
    "}\n",
    "\n",
    "current_owner_table = pd.DataFrame(data)\n",
    "\n",
    "now = datetime.utcnow().strftime('%Y-%m-%d')\n",
    "\n",
    "if not bumblebee.empty:\n",
    "    ### The filtered table is ready for upload to SF\n",
    "    # This joins the current_owner_table and the bumblebee table\n",
    "    df = bumblebee.join(current_owner_table.set_index('account_id'), on='account_id')\n",
    "\n",
    "    # this filters the table on current_owner_id in Teradata compared to owner_id in SF, and also on the intended employee_sf_id to the current owner_id in SF\n",
    "    filtered_table = df.drop(df[(df['current_owner_id'] != df['owner_id']) | (df['owner_id'] == df['employee_sf_id']) | (df['change_date'] == now)].index)\n",
    "\n",
    "    # this drops unnecesary columns\n",
    "    filtered_table.drop('current_owner_id', axis=1, inplace=True)\n",
    "    filtered_table.drop('owner_id', axis=1, inplace=True)\n",
    "    filtered_table.drop('change_date', axis=1, inplace=True)\n",
    "\n",
    "    # columns are renamed to fit Salesforce names\n",
    "    filtered_table.columns = ['Id','OwnerId']\n",
    "\n",
    "    ready_for_upload = []\n",
    "\n",
    "    for row in filtered_table.itertuples():\n",
    "        d = row._asdict()\n",
    "        del d['Index']\n",
    "        ready_for_upload.append(d)\n",
    "        \n",
    "    login_sf.bulk.Account.update(ready_for_upload,batch_size=10000,use_serial=True)\n",
    "    \n",
    "    for row in ready_for_upload:\n",
    "        try:\n",
    "            Id = row['Id']\n",
    "            OwnerId = row['OwnerId']\n",
    "            load_date = load_date = str(date.today())\n",
    "            query = f\"INSERT INTO sandbox.bumblebee_processed_changes ('{Id}','{OwnerId}','{load_date}')\"\n",
    "            pd.read_sql_query(query,con)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print('Processed changes: Success')\n",
    "\n",
    "    ### Error conditions to check\n",
    "    conditions = [\n",
    "        (df['owner_id'] == df['employee_sf_id']),\n",
    "        (df['current_owner_id'] != df['owner_id'])\n",
    "        ]\n",
    "    ### status to show in error table\n",
    "    values = [\n",
    "        'Account has already been moved to the intended owner',\n",
    "        'Account-ownership is different in Teradata and Salesforce, indicating change has already been made'\n",
    "        ]\n",
    "\n",
    "    df['Status'] = np.select(conditions,values)\n",
    "\n",
    "    ### prepare table for upload\n",
    "    error_table = df.drop(df[(df['Status'] == '0')].index)\n",
    "    error_table.drop('current_owner_id', axis=1, inplace=True)\n",
    "    error_table.drop('employee_sf_id', axis=1, inplace=True)\n",
    "    error_table.drop('owner_id', axis=1, inplace=True)\n",
    "\n",
    "    errors_for_upload = []\n",
    "\n",
    "    for row in error_table.itertuples():\n",
    "        d = row._asdict()\n",
    "        del d['Index']\n",
    "        errors_for_upload.append(d)\n",
    "\n",
    "    ### data is uploaded to Teradata\n",
    "    for row in errors_for_upload:\n",
    "        account_id = row['account_id']\n",
    "        status = row['Status']\n",
    "        load_date = str(date.today())\n",
    "        query = f\"INSERT INTO sandbox.bumblebee_errors ('{account_id}','{status}','{load_date}')\"\n",
    "        \n",
    "        pd.read_sql_query(query,con)\n",
    "        \n",
    "    print(\"Error upload: Success\")\n",
    "\n",
    "else:\n",
    "    print(\"No data in Bumblebee\")\n",
    "    exit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "414c148522c3452b8bca3bc99b333facd4b5aaa0d0e2364d6105bb7336ba2f62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
